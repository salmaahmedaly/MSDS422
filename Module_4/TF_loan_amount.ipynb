{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, PReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import functions as f\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a model using Tensor Flow that will predict Loan Default. \n",
    "For your model, do the following:\n",
    "Try at least three different Activation Functions\n",
    "Try one and two hidden layers\n",
    "Try using a Dropout Layer\n",
    "Explore using a variable selection technique\n",
    "For each of the models\n",
    "Calculate the accuracy of the model on both the training and test data set\n",
    "Create a graph that shows the ROC curves for both the training and test data set. Clearly label each curve and display the Area Under the ROC curve.\n",
    "Display a ROC curve for the test data with all your models on the same graph (tree based, regression, and TF). Discuss which one is the most accurate. Which one would you recommend using?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file and save as a dict\n",
    "winners_dict = open('../Module_3/winners.json')\n",
    "winners_dict = json.load(winners_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_a = 'TARGET_BAD_FLAG'\n",
    "target_b = 'IMP_O_TARGET_LOSS_AMT'\n",
    "\n",
    "keep_features= winners_dict['sfs_best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = f.clean_df(file_path= '../../data_sets/SA_clean_O_fixed_HMEQ_Loss.csv', remove_cols=['z_JOB', 'z_REASON','flag_LOAN', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = list(df.columns.difference((target_a, target_b)))\n",
    "x_train, x_test, y_train, y_test = f.split_df(df = df.copy(), train_cols=train_cols, \n",
    "test_cols = [target_a, target_b], test_size=0.2, rand_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the train and test splits only on values with amount > 0 \n",
    "#in clean up steps, missing amounts were filled with 0s...\n",
    "#there were no zeros in the column prior to that\n",
    "reg_y_train = y_train[y_train[target_a]==1]\n",
    "reg_y_test = y_test[y_test[target_a]==1]\n",
    "#subsetting based on index\n",
    "reg_x_train =x_train[x_train.index.isin(reg_y_train.index)]  \n",
    "reg_x_test = x_test[x_test.index.isin(reg_y_test.index)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theScaler = MinMaxScaler()\n",
    "theScaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train = pd.DataFrame(theScaler.transform(reg_x_train))\n",
    "u_test = pd.DataFrame(theScaler.transform(reg_x_test))\n",
    "u_train.columns = list(reg_x_train.columns.values)\n",
    "u_test.columns = list(reg_x_train.columns.values)\n",
    "u_train_sub= u_train[keep_features]\n",
    "u_test_sub= u_test[keep_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defaults \n",
    "theShapeSize_1 = u_train_sub.shape[1] #the number of input variables \n",
    "theActivation_1 = tf.keras.activations.relu\n",
    "output_activation_1 = tf.keras.activations.linear\n",
    "theLossMetric_1 = tf.keras.losses.MeanAbsoluteError()\n",
    "theOptimizer_1 = tf.keras.optimizers.Adam()\n",
    "theEpochs_1 = 800\n",
    "theUnits_1 = int(2*theShapeSize_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full model \n",
    "#I hidden layer\n",
    "#relu activation function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(941, 35)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(941,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_y_train[target_b].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c8e7d91e0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theShapeSize_full = u_train.shape[1] #the number of input variables \n",
    "theUnits_full = int(2*theShapeSize_full)\n",
    "\n",
    "LAYER_01 = tf.keras.layers.Dense( units=theUnits_full, activation=theActivation_1, input_dim=theShapeSize_full )\n",
    "LAYER_OUTPUT = tf.keras.layers.Dense(units=1, activation=output_activation_1 )\n",
    "\n",
    "full_model = tf.keras.Sequential()\n",
    "full_model.add( LAYER_01)\n",
    "full_model.add( LAYER_OUTPUT)\n",
    "\n",
    "full_model.compile( loss=theLossMetric_1,optimizer=theOptimizer_1)\n",
    "full_model.fit( u_train, reg_y_train[target_b], epochs=theEpochs_1, verbose=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 963us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "TF Accuracy\n",
      "======\n",
      "TF Train  =  5893.94806635929\n",
      "TF Test  =  6293.573737216157\n",
      "------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc_full = f.getAmtAccuracyScores('TF Train', full_model, u_train, reg_y_train[target_b])\n",
    "test_acc_full = f.getAmtAccuracyScores('TF Test', full_model, u_test, reg_y_test[target_b])\n",
    "f.print_Accuracy('TF Accuracy', [train_acc_full,test_acc_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "#I hidden layer\n",
    "#relu activation function\n",
    "#feature selected from forward variable selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c84439c00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "LAYER_01_01 = tf.keras.layers.Dense( units=theUnits_1, activation=theActivation_1, input_dim=theShapeSize_1 )\n",
    "LAYER_OUTPUT_01 = tf.keras.layers.Dense( units=1, activation=output_activation_1 )\n",
    "\n",
    "model_01 = tf.keras.Sequential()\n",
    "model_01.add( LAYER_01_01)\n",
    "model_01.add( LAYER_OUTPUT_01 )\n",
    "\n",
    "model_01.compile( loss=theLossMetric_1,optimizer=theOptimizer_1)\n",
    "model_01.fit( u_train_sub, reg_y_train[target_b], epochs=theEpochs_1, verbose=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "train_acc_01 = f.getAmtAccuracyScores('TF Train', model_01, u_train_sub, reg_y_train[target_b])\n",
    "test_acc_01 = f.getAmtAccuracyScores('TF Test', model_01, u_test_sub, reg_y_test[target_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Accuracy\n",
      "======\n",
      "TF Train  =  7116.658156762224\n",
      "TF Test  =  7345.703117185917\n",
      "------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f.print_Accuracy('TF Accuracy', [train_acc_01,test_acc_01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2\n",
    "#2 hidden layer\n",
    "#relu activation function\n",
    "#feature selected from forward variable selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c82115fc0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAYER_02_01 = tf.keras.layers.Dense( units=theUnits_1, activation=theActivation_1, input_dim=theShapeSize_1 )\n",
    "LAYER_02_02 = tf.keras.layers.Dense( units=theUnits_1, activation=theActivation_1 )\n",
    "LAYER_OUTPUT_02 = tf.keras.layers.Dense( units=1, activation=output_activation_1 )\n",
    "\n",
    "model_02 = tf.keras.Sequential()\n",
    "model_02.add( LAYER_02_01)\n",
    "model_02.add( LAYER_02_02)\n",
    "model_02.add( LAYER_OUTPUT_02 )\n",
    "\n",
    "model_02.compile( loss=theLossMetric_1,optimizer=theOptimizer_1)\n",
    "model_02.fit( u_train_sub, reg_y_train[target_b], epochs=theEpochs_1, verbose=False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "TF Accuracy\n",
      "======\n",
      "TF Train  =  3379.978538926695\n",
      "TF Test  =  3121.0223721770053\n",
      "------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc_02= f.getAmtAccuracyScores('TF Train', model_02, u_train_sub, reg_y_train[target_b])\n",
    "test_acc_02 = f.getAmtAccuracyScores('TF Test', model_02, u_test_sub, reg_y_test[target_b])\n",
    "f.print_Accuracy('TF Accuracy', [train_acc_02,test_acc_02])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3\n",
    "#2 hidden layer\n",
    "#drop layer\n",
    "#relu activation function\n",
    "#feature selected from forward variable selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c89e150c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAYER_03_01 = tf.keras.layers.Dense( units=theUnits_1, activation=theActivation_1, input_dim=theShapeSize_1 )\n",
    "LAYER_03_02 = tf.keras.layers.Dense( units=theUnits_1, activation=theActivation_1 )\n",
    "LAYER_DROP = tf.keras.layers.Dropout( 0.4)\n",
    "LAYER_OUTPUT_03 = tf.keras.layers.Dense( units=1, activation=output_activation_1 )\n",
    "\n",
    "model_03 = tf.keras.Sequential()\n",
    "model_03.add( LAYER_03_01)\n",
    "model_03.add( LAYER_03_02)\n",
    "model_03.add( LAYER_DROP)\n",
    "model_03.add( LAYER_OUTPUT_03 )\n",
    "\n",
    "model_03.compile( loss=theLossMetric_1,optimizer=theOptimizer_1)\n",
    "model_03.fit( u_train_sub, reg_y_train[target_b], epochs=theEpochs_1, verbose=False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 964us/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "TF Accuracy\n",
      "======\n",
      "TF Train  =  3134.120978978606\n",
      "TF Test  =  3057.785608558624\n",
      "------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc_03= f.getAmtAccuracyScores('TF Train', model_03, u_train_sub, reg_y_train[target_b])\n",
    "test_acc_03 = f.getAmtAccuracyScores('TF Test', model_03, u_test_sub, reg_y_test[target_b])\n",
    "f.print_Accuracy('TF Accuracy', [train_acc_03,test_acc_03])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeating best model () with LeakyReLU activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c821011e0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theActivation_04 = LeakyReLU(alpha=0.01)\n",
    "LAYER_04_01 = tf.keras.layers.Dense( units=theUnits_1, activation=theActivation_04, input_dim=theShapeSize_1 )\n",
    "LAYER_04_02 = tf.keras.layers.Dense( units=theUnits_1, activation=theActivation_04 )\n",
    "LAYER_DROP = tf.keras.layers.Dropout( 0.4)\n",
    "LAYER_OUTPUT_04 = tf.keras.layers.Dense( units=1, activation=output_activation_1 )\n",
    "\n",
    "model_04 = tf.keras.Sequential()\n",
    "model_04.add( LAYER_04_01)\n",
    "model_04.add( LAYER_04_02)\n",
    "model_04.add( LAYER_DROP)\n",
    "model_04.add( LAYER_OUTPUT_04 )\n",
    "\n",
    "model_04.compile( loss=theLossMetric_1,optimizer=theOptimizer_1)\n",
    "model_04.fit( u_train_sub, reg_y_train[target_b], epochs=theEpochs_1, verbose=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "TF Accuracy\n",
      "======\n",
      "TF Train  =  2786.499700316053\n",
      "TF Test  =  2690.7944224460034\n",
      "------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc_04= f.getAmtAccuracyScores('TF Train', model_04, u_train_sub, reg_y_train[target_b])\n",
    "test_acc_04 = f.getAmtAccuracyScores('TF Test', model_04, u_test_sub, reg_y_test[target_b])\n",
    "f.print_Accuracy('TF Accuracy', [train_acc_04,test_acc_04])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeating best model () with PRelue activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c8554b190>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theActivation_05 = PReLU()\n",
    "LAYER_05_01 = tf.keras.layers.Dense( units=theUnits_1, activation=theActivation_05, input_dim=theShapeSize_1 )\n",
    "LAYER_05_02 = tf.keras.layers.Dense( units=theUnits_1, activation=theActivation_05 )\n",
    "LAYER_DROP = tf.keras.layers.Dropout( 0.4)\n",
    "LAYER_OUTPUT_05 = tf.keras.layers.Dense( units=1, activation=output_activation_1 )\n",
    "\n",
    "model_05 = tf.keras.Sequential()\n",
    "model_05.add( LAYER_05_01)\n",
    "model_05.add( LAYER_05_02)\n",
    "model_05.add( LAYER_DROP)\n",
    "model_05.add( LAYER_OUTPUT_05 )\n",
    "\n",
    "model_05.compile( loss=theLossMetric_1,optimizer=theOptimizer_1)\n",
    "model_05.fit( u_train_sub, reg_y_train[target_b], epochs=theEpochs_1, verbose=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "TF Accuracy\n",
      "======\n",
      "TF Train  =  2806.6837766267204\n",
      "TF Test  =  2658.520880560739\n",
      "------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_acc_05= f.getAmtAccuracyScores('TF Train', model_05, u_train_sub, reg_y_train[target_b])\n",
    "test_acc_05 = f.getAmtAccuracyScores('TF Test', model_05, u_test_sub, reg_y_test[target_b])\n",
    "f.print_Accuracy('TF Accuracy', [train_acc_05,test_acc_05])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4217bdb66c1619d3c7bf3a5f6dea8f7bd4200ce5b7b90b812037b80bad35d2ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
